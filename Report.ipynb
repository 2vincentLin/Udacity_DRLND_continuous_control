{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity DRLND Continuous Control\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "\n",
    "The choice of algorithm to solve the Unity Reacher environment is [DDPG](https://arxiv.org/abs/1509.02971). \n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "BUFFER_SIZE = int(1e6)  # replay buffer size\n",
    "BATCH_SIZE = 256        # minibatch size\n",
    "GAMMA = 0.9             # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR_ACTOR = 1e-4         # learning rate of the actor\n",
    "LR_CRITIC = 1e-4        # learning rate of the critic\n",
    "WEIGHT_DECAY = 0.0001   # L2 weight decay\n",
    "\n",
    "### Model architecture\n",
    "\n",
    "For this project, I used a slightly simple neural network, so using GPU does not actually speed up much compared to training on CPU.\n",
    "\n",
    "Actor-network\n",
    "\n",
    "| <i></i>  |input units|output units|\n",
    "|---|---|---|\n",
    "|input layer|33|128|\n",
    "|hidden layer|128|128|\n",
    "|output layer|128|4|\n",
    "\n",
    "Critic-network\n",
    "\n",
    "| <i></i>  |input units|output units|\n",
    "|---|---|---|\n",
    "|input layer|33|128|\n",
    "|hidden layer|128+4|128|\n",
    "|output layer|128|1|\n",
    "\n",
    "I also add batch normalization layer on most layers except before input and after output layer of Critic-network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. load the necessary package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%aimport  model, test_agents\n",
    "\n",
    "from test_agents import Agent\n",
    "from model import Actor, Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "states shape:  (20, 33)\n"
     ]
    }
   ],
   "source": [
    "# file = 'One_agent/Reacher.exe'\n",
    "file = '20_agents/Reacher.exe'\n",
    "env = UnityEnvironment(file_name=file)\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "print('states shape: ', states.shape)\n",
    "state_size = states.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. training control\n",
    "\n",
    "Due to the long training time, I come up with a simple idea to be able to stop and continue the training without losing any progress. I create a python dictionary called log to store some hyperparameters like total_episodes, etc. Then I use another python script called log_control to check and modify log. To be able to stop the training anytime I want, there is an item whose key called 'end_now', if I want to end the training, I simply call end_now() in log_control.py, then before the next episode, ddpg() will check if it's True, if yes, then ddpg() ends the training right away. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "log = {\n",
    "    'total_episodes': 120, \n",
    "    'current_episodes': 0,\n",
    "    'scores': [], # store the score for every episode\n",
    "    'save_every': 30,\n",
    "    'print_every': 30, \n",
    "    'end_now': False, # use log_control.py to modify this to end the training before next episode start\n",
    "    'solved': False,\n",
    "    'solved_score':30, # score that we consider the environment is solved\n",
    "    'solve_in_episodes': None\n",
    "}\n",
    "\n",
    "import os.path\n",
    "log_path = 'log.pkl'\n",
    "\n",
    "def save_log(log_path, log):\n",
    "    with open(log_path, 'wb') as f: \n",
    "        pickle.dump(log, f)\n",
    "def load_log(log_path):\n",
    "    with open(log_path, 'rb') as f: \n",
    "        log = pickle.load(f)\n",
    "    return log\n",
    "\n",
    "# if you need to start over then uncomment the next line\n",
    "# save_log(log_path, log)\n",
    "\n",
    "if os.path.exists(log_path):\n",
    "    log = load_log(log_path)\n",
    "else:\n",
    "    save_log(log_path, log)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 30\tAverage Score: 4.27\tScore: 14.40\n",
      "Episode 60\tAverage Score: 19.77\tScore: 39.05\n",
      "Episode 90\tAverage Score: 26.13\tScore: 37.40\n",
      "Episode 108\tAverage Score: 30.23\tScore: 37.41\n",
      "environment solved in 108th episodes\n",
      "Episode 120\tAverage Score: 34.49\tScore: 37.86\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22h 35min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "agent = Agent(state_size=state_size, action_size=action_size, num_agents=num_agents, num_process=10,random_seed=0)\n",
    "\n",
    "\n",
    "def ddpg(max_t=1000, log=log, log_path=log_path):\n",
    "    # ----------load variables\n",
    "    total_episodes = log['total_episodes']\n",
    "    current_episodes = log['current_episodes']\n",
    "    scores = log['scores']\n",
    "    save_every = log['save_every']\n",
    "    print_every = log['print_every']\n",
    "    solved = log['solved']\n",
    "    solved_score = log['solved_score']\n",
    "    scores_deque = deque(maxlen=100)\n",
    "\n",
    "    # ----------load weights and scores_deque if continue training\n",
    "    if current_episodes != 0:\n",
    "        agent.load_weights()\n",
    "        [scores_deque.append(e) for e in scores]\n",
    "\n",
    "    for i_episode in range(current_episodes + 1, total_episodes + 1):\n",
    "\n",
    "        # -----check if need to end the training-------\n",
    "        log = load_log(log_path)\n",
    "        if log['end_now']:\n",
    "            log['end_now'] = False\n",
    "            log['current_episodes'] = i_episode-1 # this episodes hasn't started yet\n",
    "            save_log(log_path, log)\n",
    "            agent.save_weights()\n",
    "            break\n",
    "\n",
    "        # -----generating state--------\n",
    "        env_info = env.reset(train_mode=True)[brain_name]  # reset the environment    \n",
    "        states = env_info.vector_observations  # get the current state (for each agent)\n",
    "        agent.reset()\n",
    "        score = 0\n",
    "\n",
    "        for t in range(max_t):\n",
    "            actions = agent.act(states)\n",
    "            env_info = env.step(actions)[brain_name]  # send all actions to tne environment\n",
    "            next_states = env_info.vector_observations  # get next state (for each agent)\n",
    "            rewards = env_info.rewards  # get reward (for each agent)\n",
    "            dones = env_info.local_done  # see if episode finished\n",
    "            agent.step(states, actions, rewards, next_states, dones)\n",
    "            states = next_states\n",
    "            score += np.mean(rewards)\n",
    "            if np.any(dones):\n",
    "                break\n",
    "        scores_deque.append(score)\n",
    "        scores.append(score)\n",
    "\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}\\tScore: {:.2f}'.format(i_episode, np.mean(scores_deque), score), end=\"\")\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "            \n",
    "        # -----------if solved, store model weights and log------------------\n",
    "        if np.mean(scores_deque) > solved_score and solved == False:\n",
    "            print('\\nenvironment solved in {}th episodes'.format(i_episode))\n",
    "            solved = True\n",
    "            log['solved'] = True\n",
    "            log['solve_in_episodes'] = i_episode\n",
    "            agent.save_weights()\n",
    "            save_log(log_path, log)\n",
    "            \n",
    "        # ------------ save progress----------\n",
    "        if i_episode % save_every == 0 or i_episode == total_episodes:\n",
    "            log['current_episodes'] = i_episode\n",
    "            log['scores'] = scores\n",
    "            save_log(log_path, log)\n",
    "            agent.save_weights()\n",
    "#     if np.mean(scores_deque) > solved_score:\n",
    "#         agent.save_weights()\n",
    "    return scores\n",
    "\n",
    "\n",
    "scores = ddpg()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores) + 1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size=state_size, action_size=action_size, num_agents=num_agents, num_process=10,random_seed=0)\n",
    "agent.load_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 38.11249914811924\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = agent.act(states)                        # select an action (for each agent)\n",
    "\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Future improve\n",
    "\n",
    "When first time I ran the 20 agents version of this environment, it took my AMD 12 cores CPU and Nvidia GTX 1080 GPU over three days to run 300 episodes. One of the reason is that I only utilized one CPU core and one GPU. Then I thought, if I can come up a way to utilize more computing power, then I'd be able to try more combinations of hyperparameters in the same amount of the time. Next, I spend the whole week trying to use torch.multiprocessing to utilize multiple cores training the models. In the end, I did it, I spawn 20 subprocesses(`Process(target=agent.learn, ...)`, using Queue() to send them experiences to train. Just one problem, it only works in CPU mode, I was unable to use CUDA. I also tried other methods like sending subprocesses the model_dict() and rebuild the model, train then send back model_dict(), but I still couldn't use CUDA(at least in Windows).\n",
    "\n",
    "Another parallel package I also tried is ipyparallel, but it still suffers the same problem: you won't be able to use CUDA. However, ipyparallel seems to have more restriction comparing to torch.multiprocessing.\n",
    "\n",
    "There are some future works for me to explore and improve this project:\n",
    "\n",
    "1. Modify the 20 subprocesses part, combining subprocesses and threads to consume less resource(20 processes plus training on CPU is too much to handle on my local machine). \n",
    "2. Try to run the code under Linux. Some source said the only way to use torch.multiprocessing and CUDA together(torch version <= 0.41) is under Linux.\n",
    "3. I shouldn't need 20 critics or 20 actors, I can collect 20 actors output then send to one critic to learn. By using one common critic, it should greatly improve learning speed.\n",
    "4. Implementing D4PG.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
